{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p> Astronomer Starship can send your Airflow workloads to new places! </p>"},{"location":"#what-is-it","title":"What is it?","text":"<p>Starship is a utility to migrate Airflow metadata such as Airflow Variables, Connections, Environment Variables, Pools, and DAG History between two Airflow instances.</p> <p> </p>"},{"location":"#installation","title":"Installation","text":"<pre><code>pip install astronomer-starship\n</code></pre>"},{"location":"#usage","title":"Usage","text":"<ol> <li>Create a Workspace in Astro or Software to hold Astro Deployments</li> <li>Create an Astro Deployment matching the source Airflow deployment configuration as possible</li> <li>Run <code>astro dev init</code> with the Astro CLI to create a Astro Project locally in your terminal</li> <li>Add any DAGs to the <code>/dags</code> folder in the Astro Project</li> <li>Complete any additional setup required to convert your existing Airflow deployment to an Astro Project</li> <li>Install Starship (and any additional Python Dependencies) to the Astro Project</li> <li>Install Starship to your existing Airflow Deployment</li> <li>Deploy the Astro Project to the Astro Deployment with <code>astro deploy</code></li> <li>In the Airflow UI of the source Airflow deployment, navigate to the new <code>Astronomer</code> menu and select the <code>Migration Tool \ud83d\ude80</code> option</li> <li>Follow the UI prompts to migrate, or if needed, look at the instructions to use the Operator</li> </ol>"},{"location":"#compatability","title":"Compatability","text":"Source Compatible Airflow 1 \u274c GCC 1 - Airflow 2.x Operator GCC 2 - Airflow 2.x \u2705 MWAA v2.0.2 Operator MWAA \u2265 v2.2.2 \u2705 OSS Airflow VM \u2705 Astronomer Products \u2705"},{"location":"#faq","title":"FAQ","text":"<ul> <li> <p>I'm on Airflow 1, can I use Starship?</p> <p>No, Starship is only compatible with Airflow 2.x and above, see Compatibility</p> </li> <li> <p>I'm on Airflow&gt;=2.7 and can't test connections?</p> </li> </ul> <p>You must have <code>AIRFLOW__CORE__TEST_CONNECTION</code> set. See notes here</p> <ul> <li> <p>I'm using Google Cloud Composer 2.x and Airflow 2.x and do not see the <code>Astronomer</code> menu and/or the Starship Airflow Plugin?</p> <p>Run the following to ensure you are a privileged user. <pre><code>gcloud config set project &lt;PROJECT_NAME&gt;\ngcloud composer environments run &lt;ENVIRONMENT_NAME&gt; --location &lt;LOCATION&gt; users add-role -- -e &lt;USER_EMAIL&gt; -r Admin\n</code></pre></p> </li> </ul>"},{"location":"#security-notice","title":"Security Notice","text":"<p>This project is an Airflow Plugin that adds custom API routes. Ensure your environments are correctly secured.</p> <p>Artwork Starship logo by Lorenzo used with permission from The Noun Project under Creative Commons.</p>"},{"location":"api/","title":"API","text":""},{"location":"api/#error-responses","title":"Error Responses","text":"<p>In the event of an error, the API will return a JSON response with an <code>error</code> key and an HTTP <code>status_code</code>. The <code>error</code> key will contain a message describing the error.</p> Type Status Code Response Example Request kwargs - RuntimeError 400 <code>{\"error\": \"...\"}</code> Request kwargs - Exception 500 <code>{\"error\": \"Unknown Error in kwargs_fn - ...\"}</code> Unknown Error 500 <code>{\"error\": \"Unknown Error\", \"error_type\": ..., \"error_message\": ..., \"kwargs\": ...}</code> <code>POST</code> Integrity Error 409 <code>{\"error\": \"Integrity Error (Duplicate Record?)\", \"error_message\": ..., \"kwargs\": ...}</code> <code>POST</code> Data Error 400 <code>{\"error\": \"Data Error\", \"error_message\": ..., \"kwargs\": ...}</code> <code>POST</code> SQL Error 400 <code>{\"error\": \"SQL Error\", \"error_message\": ..., \"kwargs\": ...}</code>"},{"location":"api/#airflow-version","title":"Airflow Version","text":"<p>Returns the version of Airflow that the Starship API is connected to.</p> <p>DEPRECATED: Instead use <code>/api/starship/info</code> to get both Airflow and Starship versions plus additional information.</p>"},{"location":"api/#astronomer_starship.starship_api.StarshipApi.airflow_version--get-apistarshipairflow_version","title":"<code>GET /api/starship/airflow_version</code>","text":"<p>Parameters: None</p> <p>Response: <pre><code>2.11.0+astro.1\n</code></pre></p>"},{"location":"api/#starship-info","title":"Starship Info","text":"<p>Returns relevant information related to Starship and the Airflow deployment.</p>"},{"location":"api/#astronomer_starship.starship_api.StarshipApi.info--get-apistarshipinfo","title":"<code>GET /api/starship/info</code>","text":"<p>Parameters: None</p> <p>Response: <pre><code>{\n  \"airflow_version\": \"2.11.0+astro.1\",\n  \"starship_version\": \"2.5.0\",\n}\n</code></pre></p>"},{"location":"api/#health","title":"Health","text":"<p>Returns the health of the Starship API</p> <p>DEPRECATED: Instead use <code>/api/starship/info</code> which provides the same functionality and additional information about Airflow and Starship.</p>"},{"location":"api/#astronomer_starship.starship_api.StarshipApi.health--get-apistarshiphealth","title":"<code>GET /api/starship/health</code>","text":"<p>Parameters: None</p> <p>Response: <pre><code>OK\n</code></pre></p>"},{"location":"api/#environment-variables","title":"Environment Variables","text":"<p>Get the Environment Variables, which may be used to set Airflow Connections, Variables, or Configurations</p>"},{"location":"api/#astronomer_starship.starship_api.StarshipApi.env_vars--get-apistarshipenv_vars","title":"<code>GET /api/starship/env_vars</code>","text":"<p>Parameters: None</p> <p>Response: <pre><code>{\n    \"FOO\": \"bar\",\n    \"AIRFLOW__CORE__SQL_ALCHEMY_CONN\": \"sqlite:////usr/local/airflow/airflow.db\",\n    ...\n}\n</code></pre></p>"},{"location":"api/#variable","title":"Variable","text":"<p>Get Variables or set a Variable</p> <p>Model: <code>airflow.models.Variable</code></p> <p>Table: <code>variable</code></p>"},{"location":"api/#astronomer_starship.starship_api.StarshipApi.variables--get-apistarshipvariable","title":"<code>GET /api/starship/variable</code>","text":"<p>Parameters: None</p> <p>Response: <pre><code>[\n    {\n        \"key\": \"key\",\n        \"val\": \"val\",\n        \"description\": \"My Var\"\n    },\n    ...\n]\n</code></pre></p>"},{"location":"api/#astronomer_starship.starship_api.StarshipApi.variables--post-apistarshipvariable","title":"<code>POST /api/starship/variable</code>","text":"<p>Parameters: JSON</p> Field (*=Required) Version Type Example key* str key val* str val description str My Var <p>Response: List of Variables, as <code>GET</code> Response</p>"},{"location":"api/#astronomer_starship.starship_api.StarshipApi.variables--delete-apistarshipvariable","title":"<code>DELETE /api/starship/variable</code>","text":"<p>Parameters: Args</p> Field (*=Required) Version Type Example key* str key <p>Response: None</p>"},{"location":"api/#pools","title":"Pools","text":"<p>Get Pools or set a Pool</p> <p>Model: <code>airflow.models.Pool</code></p> <p>Table: <code>pools</code></p>"},{"location":"api/#astronomer_starship.starship_api.StarshipApi.pools--get-apistarshippools","title":"GET /api/starship/pools","text":"<p>Parameters: None</p> <p>Response: <pre><code>[\n    {\n        \"name\": \"my_pool\",\n        \"slots\": 5,\n        \"description\": \"My Pool\n    },\n    ...\n]\n</code></pre></p>"},{"location":"api/#astronomer_starship.starship_api.StarshipApi.pools--post-apistarshippools","title":"POST /api/starship/pools","text":"<p>Parameters: JSON</p> Field (*=Required) Version Type Example name* str my_pool slots* int 5 description str My Pool include_deferred* &gt;=2.7 bool True <p>Response: List of Pools, as <code>GET</code> Response</p>"},{"location":"api/#astronomer_starship.starship_api.StarshipApi.pools--delete-apistarshippools","title":"DELETE /api/starship/pools","text":"<p>Parameters: Args</p> Field (*=Required) Version Type Example name* str my_pool <p>Response: None</p>"},{"location":"api/#connections","title":"Connections","text":"<p>Get Connections or set a Connection</p> <p>Model: <code>airflow.models.Connections</code></p> <p>Table: <code>connection</code></p>"},{"location":"api/#astronomer_starship.starship_api.StarshipApi.connections--get-apistarshipconnection","title":"<code>GET /api/starship/connection</code>","text":"<p>Parameters: None</p> <p>Response: <pre><code>[\n    {\n        \"conn_id\": \"my_conn\",\n        \"conn_type\": \"http\",\n        \"host\": \"localhost\",\n        \"port\": \"1234\",\n        \"schema\": \"https\",\n        \"login\": \"user\",\n        \"password\": \"foobar\",  # pragma: allowlist secret\n        \"extra\": \"{}\",\n        \"conn_type\": \"http\",\n        \"conn_type\": \"http\",\n        \"conn_type\": \"http\",\n        \"description\": \"My Var\"\n    },\n    ...\n]\n</code></pre></p>"},{"location":"api/#astronomer_starship.starship_api.StarshipApi.connections--post-apistarshipconnection","title":"<code>POST /api/starship/connection</code>","text":"<p>Parameters: JSON</p> Field (*=Required) Version Type Example conn_id* str my_conn conn_type* str http host str localhost port int 1234 schema str https login str user password str ** extra dict {} description str My Conn <p>Response: List of Connections, as <code>GET</code> Response</p>"},{"location":"api/#astronomer_starship.starship_api.StarshipApi.connections--delete-apistarshipconnections","title":"DELETE /api/starship/connections","text":"<p>Parameters: Args</p> Field (*=Required) Version Type Example conn_id* str my_conn <p>Response: None</p>"},{"location":"api/#dags","title":"DAGs","text":"<p>Get DAG or pause/unpause a DAG</p> <p>Model: <code>airflow.models.DagModel</code></p> <p>Table: <code>dags</code></p>"},{"location":"api/#astronomer_starship.starship_api.StarshipApi.dags--get-apistarshipdags","title":"<code>GET /api/starship/dags</code>","text":"<p>Parameters: None</p> <p>Response: <pre><code>[\n    {\n        \"dag_id\": \"dag_0\",\n        \"schedule_interval\": \"0 0 * * *\",\n        \"is_paused\": true,\n        \"fileloc\": \"/usr/local/airflow/dags/dag_0.py\",\n        \"description\": \"My Dag\",\n        \"owners\": \"user\",\n        \"tags\": [\"tag1\", \"tag2\"],\n        \"dag_run_count\": 2,\n    },\n    ...\n]\n</code></pre></p>"},{"location":"api/#astronomer_starship.starship_api.StarshipApi.dags--patch-apistarshipdags","title":"<code>PATCH /api/starship/dags</code>","text":"<p>Parameters: JSON</p> Field (*=Required) Version Type Example dag_id* str dag_0 is_paused* bool true <pre><code>{\n    \"dag_id\": \"dag_0\",\n    \"is_paused\": true\n}\n</code></pre>"},{"location":"api/#dag-runs","title":"DAG Runs","text":"<p>Get DAG Runs or set DAG Runs</p> <p>Model: <code>airflow.models.DagRun</code></p> <p>Table: <code>dag_run</code></p>"},{"location":"api/#astronomer_starship.starship_api.StarshipApi.dag_runs--get-apistarshipdag_runs","title":"<code>GET /api/starship/dag_runs</code>","text":"<p>Parameters: Args</p> Field (*=Required) Version Type Example dag_id* str dag_0 limit int 10 offset int 0 <p>Response: <pre><code>{\n    \"dag_run_count\": 1,\n    \"dag_runs\":\n        [\n            {\n                \"dag_id\": \"dag_0\",\n                \"queued_at\": \"1970-01-01T00:00:00+00:00\",\n                \"execution_date\": \"1970-01-01T00:00:00+00:00\",\n                \"start_date\": \"1970-01-01T00:00:00+00:00\",\n                \"end_date\": \"1970-01-01T00:00:00+00:00\",\n                \"state\": \"SUCCESS\",\n                \"run_id\": \"manual__1970-01-01T00:00:00+00:00\",\n                \"creating_job_id\": 123,\n                \"external_trigger\": true,\n                \"run_type\": \"manual\",\n                \"conf\": {\"my_param\": \"my_value\"},\n                \"data_interval_start\": \"1970-01-01T00:00:00+00:00\",\n                \"data_interval_end\": \"1970-01-01T00:00:00+00:00\",\n                \"last_scheduling_decision\": \"1970-01-01T00:00:00+00:00\",\n                \"dag_hash\": \"....\"\n            },\n            ...\n        ]\n}\n</code></pre></p>"},{"location":"api/#astronomer_starship.starship_api.StarshipApi.dag_runs--post-apistarshipdag_runs","title":"<code>POST /api/starship/dag_runs</code>","text":"<p>Parameters: JSON</p> Field (*=Required) Version Type Example dag_runs list[DagRun] [ ... ] <pre><code>{\n    \"dag_runs\": [ ... ]\n}\n</code></pre> <p>DAG Run:</p> Field (*=Required) Version Type Example dag_id* str dag_0 queued_at date 1970-01-01T00:00:00+00:00 execution_date* date 1970-01-01T00:00:00+00:00 start_date date 1970-01-01T00:00:00+00:00 end_date date 1970-01-01T00:00:00+00:00 state str SUCCESS run_id* str manual__1970-01-01T00:00:00+00:00 creating_job_id int 123 external_trigger bool true run_type* str manual conf dict {} data_interval_start &gt;2.1 date 1970-01-01T00:00:00+00:00 data_interval_end &gt;2.1 date 1970-01-01T00:00:00+00:00 last_scheduling_decision date 1970-01-01T00:00:00+00:00 dag_hash str ... clear_number &gt;=2.8 int 0"},{"location":"api/#astronomer_starship.starship_api.StarshipApi.dag_runs--delete-apistarshipdag_runs","title":"DELETE /api/starship/dag_runs","text":"<p>Parameters: Args</p> Field (*=Required) Version Type Example dag_id* str dag_0 <p>Response: None</p>"},{"location":"api/#task-instances","title":"Task Instances","text":"<p>Get TaskInstances or set TaskInstances</p> <p>Model: <code>airflow.models.TaskInstance</code></p> <p>Table: <code>task_instance</code></p>"},{"location":"api/#astronomer_starship.starship_api.StarshipApi.task_instances--get-apistarshiptask_instances","title":"<code>GET /api/starship/task_instances</code>","text":"<p>Parameters: Args</p> Field (*=Required) Version Type Example dag_id* str dag_0 limit int 10 offset int 0 <p>Response: <pre><code>{\n    \"task_instances\": [\n        {\n            \"task_instances\": []\n            \"run_id\": \"manual__1970-01-01T00:00:00+00:00\",\n            \"queued_at\": \"1970-01-01T00:00:00+00:00\",\n            \"execution_date\": \"1970-01-01T00:00:00+00:00\",\n            \"start_date\": \"1970-01-01T00:00:00+00:00\",\n            \"end_date\": \"1970-01-01T00:00:00+00:00\",\n            \"state\": \"SUCCESS\",\n            \"creating_job_id\": 123,\n            \"external_trigger\": true,\n            \"run_type\": \"manual\",\n            \"conf\": {\"my_param\": \"my_value\"},\n            \"data_interval_start\": \"1970-01-01T00:00:00+00:00\",\n            \"data_interval_end\": \"1970-01-01T00:00:00+00:00\",\n            \"last_scheduling_decision\": \"1970-01-01T00:00:00+00:00\",\n            \"dag_hash\": \"....\"\n        },\n        ...\n    ],\n    \"dag_run_count\": 2,\n}\n</code></pre></p>"},{"location":"api/#astronomer_starship.starship_api.StarshipApi.task_instances--post-apistarshiptask_instances","title":"<code>POST /api/starship/task_instances</code>","text":"<p>Parameters: JSON</p> Field (*=Required) Version Type Example task_instances list[TaskInstance] [ ... ] <pre><code>{\n    \"task_instances\": [ ... ]\n}\n</code></pre> <p>Task Instance:</p> Field (*=Required) Version Type Example dag_id* str dag_0 run_id* &gt;2.1 str manual__1970-01-01T00:00:00+00:00 task_id* str task_0 map_index* &gt;2.2 int -1 execution_date* &lt;=2.1 date 1970-01-01T00:00:00+00:00 start_date date 1970-01-01T00:00:00+00:00 end_date date 1970-01-01T00:00:00+00:00 duration float 0.0 max_tries int 2 hostname str host unixname str unixname job_id int 123 pool* str default_pool pool_slots int 1 queue str queue priority_weight int 1 operator str BashOperator queued_dttm date 1970-01-01T00:00:00+00:00 queued_by_job_id int 123 pid int 123 external_executor_id int trigger_id &gt;2.1 str trigger_timeout &gt;2.1 date 1970-01-01T00:00:00+00:00 executor_config str"},{"location":"api/#task-instance-history","title":"Task Instance History","text":"<p>Get and set TaskInstanceHistory records.</p> <p>Model: <code>airflow.models.TaskInstanceHistory</code></p> <p>Table: <code>task_instance_history</code></p>"},{"location":"api/#astronomer_starship.starship_api.StarshipApi.task_instance_history--get-apistarshiptask_instance_history","title":"<code>GET /api/starship/task_instance_history</code>","text":"<p>Parameters: Args</p> Field (*=Required) Version Type Example dag_id* str dag_0 limit int 10 offset int 0 <p>Response: <pre><code>{\n    \"task_instances\": [\n        {\n            \"task_instances\": []\n            \"run_id\": \"manual__1970-01-01T00:00:00+00:00\",\n            \"queued_at\": \"1970-01-01T00:00:00+00:00\",\n            \"execution_date\": \"1970-01-01T00:00:00+00:00\",\n            \"start_date\": \"1970-01-01T00:00:00+00:00\",\n            \"end_date\": \"1970-01-01T00:00:00+00:00\",\n            \"state\": \"SUCCESS\",\n            \"creating_job_id\": 123,\n            \"external_trigger\": true,\n            \"run_type\": \"manual\",\n            \"conf\": {\"my_param\": \"my_value\"},\n            \"data_interval_start\": \"1970-01-01T00:00:00+00:00\",\n            \"data_interval_end\": \"1970-01-01T00:00:00+00:00\",\n            \"last_scheduling_decision\": \"1970-01-01T00:00:00+00:00\",\n            \"dag_hash\": \"....\"\n        },\n        ...\n    ],\n    \"dag_run_count\": 2,\n}\n</code></pre></p>"},{"location":"api/#astronomer_starship.starship_api.StarshipApi.task_instance_history--post-apistarshiptask_instance_history","title":"<code>POST /api/starship/task_instance_history</code>","text":"<p>Parameters: JSON</p> Field (*=Required) Version Type Example task_instances list[TaskInstance] [ ... ] <pre><code>{\n    \"task_instances\": [ ... ]\n}\n</code></pre> <p>Task Instance:</p> Field (*=Required) Version Type Example dag_id* str dag_0 run_id* &gt;2.1 str manual__1970-01-01T00:00:00+00:00 task_id* str task_0 map_index* &gt;2.2 int -1 execution_date* &lt;=2.1 date 1970-01-01T00:00:00+00:00 start_date date 1970-01-01T00:00:00+00:00 end_date date 1970-01-01T00:00:00+00:00 duration float 0.0 max_tries int 2 hostname str host unixname str unixname job_id int 123 pool* str default_pool pool_slots int 1 queue str queue priority_weight int 1 operator str BashOperator queued_dttm date 1970-01-01T00:00:00+00:00 queued_by_job_id int 123 pid int 123 external_executor_id int trigger_id &gt;2.1 str trigger_timeout &gt;2.1 date 1970-01-01T00:00:00+00:00 executor_config str"},{"location":"api/#task-log","title":"Task Log","text":"<p>EXPERIMENTAL</p> <p>Get, set or delete task logs.</p> <p>Requirements:</p> <ul> <li>Airflow 2.8+</li> <li>Astro hosted deployments or local astro dev environment</li> </ul>"},{"location":"api/#astronomer_starship.starship_api.StarshipApi.task_logs--get-apistarshiptask_log","title":"<code>GET /api/starship/task_log</code>","text":"<p>Parameters: Args</p> Field (*=Required) Version Type Example dag_id* str dag_0 run_id* str scheduled__2025-06-30T20:00:00+00:00 task_id* str task_0 map_index* int -1 try_number* int 1 block_size int 1048576 <p>Response:</p> <pre><code>[2025-06-30T21:02:11.417+0000] ...\n\n... Task exited with return code 0\n</code></pre>"},{"location":"api/#astronomer_starship.starship_api.StarshipApi.task_logs--post-apistarshiptask_log","title":"<code>POST /api/starship/task_log</code>","text":"<p>Parameters: Args</p> Field (*=Required) Version Type Example dag_id* str dag_0 run_id* str scheduled__2025-06-30T20:00:00+00:00 task_id* str task_0 map_index* int -1 try_number* int 1 block_size int 1048576 <p>Request:</p> <pre><code>[2025-06-30T21:02:11.417+0000] ...\n\n... Task exited with return code 0\n</code></pre> <p>Response: None</p>"},{"location":"api/#astronomer_starship.starship_api.StarshipApi.task_logs--delete-apistarshiptask_log","title":"DELETE /api/starship/task_log","text":"<p>Parameters: Args</p> Field (*=Required) Version Type Example dag_id* str dag_0 run_id* str scheduled__2025-06-30T20:00:00+00:00 task_id* str task_0 map_index* int -1 try_number* int 1 <p>Response: None</p>"},{"location":"api/#xcom","title":"XCom","text":"<p>EXPERIMENTAL</p> <p>Get, set or delete XComs.</p> <p>Requirements:</p> <ul> <li>Airflow 2.8+</li> </ul>"},{"location":"api/#astronomer_starship.starship_api.StarshipApi.xcom--get-apistarshipxcom","title":"<code>GET /api/starship/xcom</code>","text":"<p>Parameters: Args</p> Field (*=Required) Version Type Example dag_id* str dag_0 run_id* str scheduled__2025-06-30T20:00:00+00:00 task_id* str task_0 map_index* int -1 <p>Response:</p> <pre><code>[\n    {\n        \"dag_id\": \"example_xcom\",\n        \"key\": \"example_str\",\n        \"map_index\": -1,\n        \"run_id\": \"scheduled__2025-07-17T00:00:00+00:00\",\n        \"task_id\": \"run\",\n        \"value\": \"bnVsbA==\"\n    }\n]\n</code></pre>"},{"location":"api/#astronomer_starship.starship_api.StarshipApi.xcom--post-apistarshiptask_log","title":"<code>POST /api/starship/task_log</code>","text":"<p>Parameters: JSON</p> Field (*=Required) Version Type Example dag_id* str dag_0 run_id* str scheduled__2025-06-30T20:00:00+00:00 task_id* str task_0 map_index* int -1 key* str return_value value* str bnVsbA== <p>Request:</p> <pre><code>{\n    \"dag_id\": \"example_xcom\",\n    \"key\": \"example_str\",\n    \"map_index\": -1,\n    \"run_id\": \"scheduled__2025-07-17T00:00:00+00:00\",\n    \"task_id\": \"run\",\n    \"value\": \"bnVsbA==\"\n}\n</code></pre> <p>Response: None</p>"},{"location":"api/#astronomer_starship.starship_api.StarshipApi.xcom--delete-apistarshiptask_log","title":"DELETE /api/starship/task_log","text":"<p>Parameters: Args</p> Field (*=Required) Version Type Example dag_id* str dag_0 run_id* str scheduled__2025-06-30T20:00:00+00:00 task_id* str task_0 map_index* int -1 <p>Response: None</p>"},{"location":"operator/","title":"Starship Migration DAG","text":"<p>The <code>StarshipAirflowMigrationDAG</code> can be used to migrate Airflow Variables, Pools, Connections, and DAG History from one Airflow instance to another.</p> <p>The <code>StarshipAirflowMigrationDAG</code> should be used in instances where the source Airflow Webserver is unable to correctly host a Plugin. The Target must still have a functioning Starship Plugin installed, be running the same version of Airflow, and have the same set of DAGs deployed.</p> <p>The <code>StarshipAirflowMigrationDAG</code> should be used if migrating from a Google Cloud Composer 1 (with Airflow 2.x) or MWAA v2.0.2 environment. These environments do not support webserver plugins and will require using the <code>StarshipAirflowMigrationDAG</code> to migrate data.</p>"},{"location":"operator/#installation","title":"Installation","text":"<p>Add the following line to your <code>requirements.txt</code> in your source environment:</p> <pre><code>astronomer-starship[provider]\n</code></pre>"},{"location":"operator/#setup","title":"Setup","text":"<p>Make a connection in Airflow with the following details: - Conn ID: <code>starship_default</code> - Conn Type: <code>HTTP</code> - Host: the URL of the homepage of Airflow (excluding <code>/home</code> on the end of the URL)   - For example, if your deployment URL is <code>https://astronomer.astronomer.run/abcdt4ry/home</code>, you'll use <code>https://astronomer.astronomer.run/abcdt4ry</code> - Schema: <code>https</code> - Extra: <code>{\"Authorization\": \"Bearer &lt;token&gt;\"}</code></p>"},{"location":"operator/#usage","title":"Usage","text":"<ol> <li> <p>Add the following DAG to your source environment:</p> dags/starship_airflow_migration_dag.py<pre><code>from astronomer_starship.providers.starship.operators.starship import (\n    StarshipAirflowMigrationDAG,\n)\n\nglobals()[\"starship_airflow_migration_dag\"] = StarshipAirflowMigrationDAG(\n    http_conn_id=\"starship_default\"\n)\n</code></pre> </li> <li> <p>Unpause the DAG in the Airflow UI</p> </li> <li>Once the DAG successfully runs, your connections, variables, and environment variables should all be migrated to Astronomer</li> </ol>"},{"location":"operator/#configuration","title":"Configuration","text":"<p>The <code>StarshipAirflowMigrationDAG</code> can be configured as follows:</p> <pre><code>StarshipAirflowMigrationDAG(\n    http_conn_id=\"starship_default\",\n    variables=None,  # None to migrate all, or [\"var1\", \"var2\"] to migrate specific items, or empty list to skip all\n    pools=None,  # None to migrate all, or [\"pool1\", \"pool2\"] to migrate specific items, or empty list to skip all\n    connections=None,  # None to migrate all, or [\"conn1\", \"conn2\"] to migrate specific items, or empty list to skip all\n    dag_ids=None,  # None to migrate all, or [\"dag1\", \"dag2\"] to migrate specific items, or empty list to skip all\n)\n</code></pre> <p>You can use this DAG to migrate all items, or specific items by providing a list of names.</p> <p>You can skip migration by providing an empty list.</p>"},{"location":"operator/#python-api","title":"Python API","text":""},{"location":"operator/#hooks","title":"Hooks","text":"<p>Hooks for interacting with Starship migrations</p> <p>Classes:</p> Name Description <code>StarshipHttpHook</code> <code>StarshipLocalHook</code> <p>Hook to retrieve local Airflow data, which can then be sent to the Target Starship instance.</p>"},{"location":"operator/#astronomer_starship.providers.starship.hooks.starship.StarshipHttpHook","title":"StarshipHttpHook","text":"<p>Methods:</p> Name Description <code>get_connections</code> <p>Get all connections from the Target Starship instance.</p> <code>get_dag_runs</code> <p>Get DAG runs from the Target Starship instance.</p> <code>get_dags</code> <p>Get all DAGs from the Target Starship instance.</p> <code>get_pools</code> <p>Get all pools from the Target Starship instance.</p> <code>get_task_instances</code> <p>Get task instances from the Target Starship instance.</p> <code>get_variables</code> <p>Get all variables from the Target Starship instance.</p> <code>set_connection</code> <p>Set a connection in the Target Starship instance.</p> <code>set_dag_is_paused</code> <p>Set the paused status of a DAG in the Target Starship instance.</p> <code>set_dag_runs</code> <p>Set DAG runs in the Target Starship instance.</p> <code>set_pool</code> <p>Set a pool in the Target Starship instance.</p> <code>set_task_instances</code> <p>Set task instances in the Target Starship instance.</p> <code>set_variable</code> <p>Set a variable in the Target Starship instance.</p>"},{"location":"operator/#astronomer_starship.providers.starship.hooks.starship.StarshipHttpHook.get_connections","title":"get_connections","text":"<pre><code>get_connections()\n</code></pre> <p>Get all connections from the Target Starship instance.</p>"},{"location":"operator/#astronomer_starship.providers.starship.hooks.starship.StarshipHttpHook.get_dag_runs","title":"get_dag_runs","text":"<pre><code>get_dag_runs(dag_id: str, offset: int = 0, limit: int = 10) -&gt; dict\n</code></pre> <p>Get DAG runs from the Target Starship instance.</p>"},{"location":"operator/#astronomer_starship.providers.starship.hooks.starship.StarshipHttpHook.get_dags","title":"get_dags","text":"<pre><code>get_dags() -&gt; dict\n</code></pre> <p>Get all DAGs from the Target Starship instance.</p>"},{"location":"operator/#astronomer_starship.providers.starship.hooks.starship.StarshipHttpHook.get_pools","title":"get_pools","text":"<pre><code>get_pools()\n</code></pre> <p>Get all pools from the Target Starship instance.</p>"},{"location":"operator/#astronomer_starship.providers.starship.hooks.starship.StarshipHttpHook.get_task_instances","title":"get_task_instances","text":"<pre><code>get_task_instances(dag_id: str, offset: int = 0, limit: int = 10)\n</code></pre> <p>Get task instances from the Target Starship instance.</p>"},{"location":"operator/#astronomer_starship.providers.starship.hooks.starship.StarshipHttpHook.get_variables","title":"get_variables","text":"<pre><code>get_variables()\n</code></pre> <p>Get all variables from the Target Starship instance.</p>"},{"location":"operator/#astronomer_starship.providers.starship.hooks.starship.StarshipHttpHook.set_connection","title":"set_connection","text":"<pre><code>set_connection(**kwargs)\n</code></pre> <p>Set a connection in the Target Starship instance.</p>"},{"location":"operator/#astronomer_starship.providers.starship.hooks.starship.StarshipHttpHook.set_dag_is_paused","title":"set_dag_is_paused","text":"<pre><code>set_dag_is_paused(dag_id: str, is_paused: bool)\n</code></pre> <p>Set the paused status of a DAG in the Target Starship instance.</p>"},{"location":"operator/#astronomer_starship.providers.starship.hooks.starship.StarshipHttpHook.set_dag_runs","title":"set_dag_runs","text":"<pre><code>set_dag_runs(dag_runs: List[dict]) -&gt; dict\n</code></pre> <p>Set DAG runs in the Target Starship instance.</p>"},{"location":"operator/#astronomer_starship.providers.starship.hooks.starship.StarshipHttpHook.set_pool","title":"set_pool","text":"<pre><code>set_pool(**kwargs)\n</code></pre> <p>Set a pool in the Target Starship instance.</p>"},{"location":"operator/#astronomer_starship.providers.starship.hooks.starship.StarshipHttpHook.set_task_instances","title":"set_task_instances","text":"<pre><code>set_task_instances(task_instances: list[dict]) -&gt; dict\n</code></pre> <p>Set task instances in the Target Starship instance.</p>"},{"location":"operator/#astronomer_starship.providers.starship.hooks.starship.StarshipHttpHook.set_variable","title":"set_variable","text":"<pre><code>set_variable(**kwargs)\n</code></pre> <p>Set a variable in the Target Starship instance.</p>"},{"location":"operator/#astronomer_starship.providers.starship.hooks.starship.StarshipLocalHook","title":"StarshipLocalHook","text":"<p>Hook to retrieve local Airflow data, which can then be sent to the Target Starship instance.</p> <p>Methods:</p> Name Description <code>get_connections</code> <p>Get all connections from the local Airflow instance.</p> <code>get_dag_runs</code> <p>Get DAG runs from the local Airflow instance.</p> <code>get_dags</code> <p>Get all DAGs from the local Airflow instance.</p> <code>get_pools</code> <p>Get all pools from the local Airflow instance.</p> <code>get_task_instances</code> <p>Get task instances from the local Airflow instance.</p> <code>get_variables</code> <p>Get all variables from the local Airflow instance.</p> <code>set_dag_is_paused</code> <p>Set the paused status of a DAG in the local Airflow instance.</p>"},{"location":"operator/#astronomer_starship.providers.starship.hooks.starship.StarshipLocalHook.get_connections","title":"get_connections","text":"<pre><code>get_connections()\n</code></pre> <p>Get all connections from the local Airflow instance.</p>"},{"location":"operator/#astronomer_starship.providers.starship.hooks.starship.StarshipLocalHook.get_dag_runs","title":"get_dag_runs","text":"<pre><code>get_dag_runs(dag_id: str, offset: int = 0, limit: int = 10) -&gt; dict\n</code></pre> <p>Get DAG runs from the local Airflow instance.</p>"},{"location":"operator/#astronomer_starship.providers.starship.hooks.starship.StarshipLocalHook.get_dags","title":"get_dags","text":"<pre><code>get_dags() -&gt; dict\n</code></pre> <p>Get all DAGs from the local Airflow instance.</p>"},{"location":"operator/#astronomer_starship.providers.starship.hooks.starship.StarshipLocalHook.get_pools","title":"get_pools","text":"<pre><code>get_pools()\n</code></pre> <p>Get all pools from the local Airflow instance.</p>"},{"location":"operator/#astronomer_starship.providers.starship.hooks.starship.StarshipLocalHook.get_task_instances","title":"get_task_instances","text":"<pre><code>get_task_instances(dag_id: str, offset: int = 0, limit: int = 10)\n</code></pre> <p>Get task instances from the local Airflow instance.</p>"},{"location":"operator/#astronomer_starship.providers.starship.hooks.starship.StarshipLocalHook.get_variables","title":"get_variables","text":"<pre><code>get_variables()\n</code></pre> <p>Get all variables from the local Airflow instance.</p>"},{"location":"operator/#astronomer_starship.providers.starship.hooks.starship.StarshipLocalHook.set_dag_is_paused","title":"set_dag_is_paused","text":"<pre><code>set_dag_is_paused(dag_id: str, is_paused: bool)\n</code></pre> <p>Set the paused status of a DAG in the local Airflow instance.</p>"},{"location":"operator/#operators-taskgroups-dag","title":"Operators, TaskGroups, DAG","text":"<p>Operators, TaskGroups, and DAGs for interacting with the Starship migrations.</p> <p>Classes:</p> Name Description <code>StarshipConnectionMigrationOperator</code> <p>Operator to migrate a single Connection from one Airflow instance to another.</p> <code>StarshipDagHistoryMigrationOperator</code> <p>Operator to migrate a single DAG from one Airflow instance to another, with it's history.</p> <code>StarshipPoolMigrationOperator</code> <p>Operator to migrate a single Pool from one Airflow instance to another.</p> <code>StarshipVariableMigrationOperator</code> <p>Operator to migrate a single Variable from one Airflow instance to another.</p> <p>Functions:</p> Name Description <code>StarshipAirflowMigrationDAG</code> <p>DAG to fetch and migrate Variables, Pools, Connections, and DAGs with history from one Airflow instance to another.</p> <code>starship_connections_migration</code> <p>TaskGroup to fetch and migrate Connections from one Airflow instance to another.</p> <code>starship_dag_history_migration</code> <p>TaskGroup to fetch and migrate DAGs with their history from one Airflow instance to another.</p> <code>starship_pools_migration</code> <p>TaskGroup to fetch and migrate Pools from one Airflow instance to another.</p> <code>starship_variables_migration</code> <p>TaskGroup to fetch and migrate Variables from one Airflow instance to another.</p>"},{"location":"operator/#astronomer_starship.providers.starship.operators.starship.StarshipConnectionMigrationOperator","title":"StarshipConnectionMigrationOperator","text":"<pre><code>StarshipConnectionMigrationOperator(connection_id: Union[str, None] = None, **kwargs)\n</code></pre> <p>Operator to migrate a single Connection from one Airflow instance to another.</p>"},{"location":"operator/#astronomer_starship.providers.starship.operators.starship.StarshipDagHistoryMigrationOperator","title":"StarshipDagHistoryMigrationOperator","text":"<pre><code>StarshipDagHistoryMigrationOperator(target_dag_id: str, unpause_dag_in_target: bool = False, dag_run_limit: int = 10, **kwargs)\n</code></pre> <p>Operator to migrate a single DAG from one Airflow instance to another, with it's history.</p>"},{"location":"operator/#astronomer_starship.providers.starship.operators.starship.StarshipPoolMigrationOperator","title":"StarshipPoolMigrationOperator","text":"<pre><code>StarshipPoolMigrationOperator(pool_name: Union[str, None] = None, **kwargs)\n</code></pre> <p>Operator to migrate a single Pool from one Airflow instance to another.</p>"},{"location":"operator/#astronomer_starship.providers.starship.operators.starship.StarshipVariableMigrationOperator","title":"StarshipVariableMigrationOperator","text":"<pre><code>StarshipVariableMigrationOperator(variable_key: Union[str, None] = None, **kwargs)\n</code></pre> <p>Operator to migrate a single Variable from one Airflow instance to another.</p>"},{"location":"operator/#astronomer_starship.providers.starship.operators.starship.StarshipAirflowMigrationDAG","title":"StarshipAirflowMigrationDAG","text":"<pre><code>StarshipAirflowMigrationDAG(http_conn_id: str, variables: List[str] = None, pools: List[str] = None, connections: List[str] = None, dag_ids: List[str] = None, **kwargs)\n</code></pre> <p>DAG to fetch and migrate Variables, Pools, Connections, and DAGs with history from one Airflow instance to another.</p>"},{"location":"operator/#astronomer_starship.providers.starship.operators.starship.starship_connections_migration","title":"starship_connections_migration","text":"<pre><code>starship_connections_migration(connections: List[str] = None, **kwargs)\n</code></pre> <p>TaskGroup to fetch and migrate Connections from one Airflow instance to another.</p>"},{"location":"operator/#astronomer_starship.providers.starship.operators.starship.starship_dag_history_migration","title":"starship_dag_history_migration","text":"<pre><code>starship_dag_history_migration(dag_ids: List[str] = None, **kwargs)\n</code></pre> <p>TaskGroup to fetch and migrate DAGs with their history from one Airflow instance to another.</p>"},{"location":"operator/#astronomer_starship.providers.starship.operators.starship.starship_pools_migration","title":"starship_pools_migration","text":"<pre><code>starship_pools_migration(pools: List[str] = None, **kwargs)\n</code></pre> <p>TaskGroup to fetch and migrate Pools from one Airflow instance to another.</p>"},{"location":"operator/#astronomer_starship.providers.starship.operators.starship.starship_variables_migration","title":"starship_variables_migration","text":"<pre><code>starship_variables_migration(variables: List[str] = None, **kwargs)\n</code></pre> <p>TaskGroup to fetch and migrate Variables from one Airflow instance to another.</p>"},{"location":"migration_source/gcc/","title":"Google Cloud Composer","text":""},{"location":"migration_source/gcc/#compatability","title":"Compatability","text":"Source Compatible Airflow 1 \u274c GCC 1 - Airflow 2.x Operator GCC 2 - Airflow 2.x \u2705"},{"location":"migration_source/gcc/#notes","title":"Notes","text":"<p>You must be an Admin to see Plugins on GCC.</p>"},{"location":"migration_source/gcc/#installation","title":"Installation","text":"<ol> <li>Navigate to your Environments</li> <li>Go to PyPi Packages     </li> <li>Click <code>+ Add Package</code> and put <code>astronomer-starship</code> under <code>Package name</code> </li> </ol>"},{"location":"migration_source/gcc/#faq","title":"FAQ","text":"<ul> <li> <p>I'm using Google Cloud Composer 2.x and Airflow 2.x and do not see the <code>Astronomer</code> menu and/or the Starship Airflow Plugin?</p> <p>Run the following to ensure you are a privileged user. <pre><code>gcloud config set project &lt;PROJECT_NAME&gt;\ngcloud composer environments run &lt;ENVIRONMENT_NAME&gt; --location &lt;LOCATION&gt; users add-role -- -e &lt;USER_EMAIL&gt; -r Admin\n</code></pre></p> </li> </ul>"},{"location":"migration_source/mwaa/","title":"(AWS) Managed Apache Airflow","text":""},{"location":"migration_source/mwaa/#compatability","title":"Compatability","text":"Source Compatible Airflow 1 \u274c MWAA v2.0.2 Operator MWAA \u2265 v2.2.2 \u2705"},{"location":"migration_source/mwaa/#installation","title":"Installation","text":"<ol> <li>Navigate to your Environments</li> <li>Download your existing <code>requirements.txt</code></li> <li>Add <code>astronomer-starship</code> to the file, save it, and re-upload it to S3</li> <li>Click <code>Edit</code>, and pick the newer version of your Requirements File     </li> <li>Click <code>Next</code>, then eventually <code>Save</code>, and then wait for your deployment to restart and dependencies to install</li> </ol>"}]}